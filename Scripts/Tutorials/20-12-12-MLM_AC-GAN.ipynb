{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "venv",
   "display_name": "venv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, ones, expand_dims, asarray\n",
    "from numpy.random import randn, randint\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Dropout, Embedding, Activation, Concatenate\n",
    "from keras.initializers import RandomNormal\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAIN FUNCS\n",
    "\n",
    "#define discriminator model\n",
    "def define_discriminator(in_shape=(28, 28, 1), n_classes = 10):\n",
    "    #weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    #image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "    #downsample to 14x14\n",
    "    fe = Conv2D(32, (3,3), strides=(2,2), padding=\"same\", kernel_initializer=init)(in_image)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = Dropout(0.5)(fe)\n",
    "    #normal\n",
    "    fe = Conv2D(64, (3,3), padding=\"same\", kernel_initializer=init)(fe)\n",
    "    fe = BatchNormalization()(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = Dropout(0.5)(fe)\n",
    "    #downsample to 7x7\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding=\"same\", kernel_initializer=init)(fe)\n",
    "    fe = BatchNormalization()(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = Dropout(0.5)(fe)\n",
    "    # normal\n",
    "    fe = Conv2D(256, (3,3), padding=\"same\", kernel_initializer=init)(fe)\n",
    "    fe = BatchNormalization()(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    fe = Dropout(0.5)(fe)\n",
    "    # flatten feature maps\n",
    "    fe = Flatten()(fe)\n",
    "    # real/fake output\n",
    "    out1 = Dense(1, activation=\"sigmoid\")(fe)\n",
    "    # class label output\n",
    "    out2 = Dense(n_classes, activation=\"softmax\")(fe)\n",
    "    # define model\n",
    "    model = Model(in_image, [out1, out2])\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=[\"binary_crossentropy\", \"sparse_categorical_crossentropy\"], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_classes=10):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # linear multiplication\n",
    "    n_nodes = 7 * 7\n",
    "    li = Dense(n_nodes, kernel_initializer=init)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((7, 7, 1))(li)\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 384 * 7 * 7\n",
    "    gen = Dense(n_nodes, kernel_initializer=init)(in_lat)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    gen = Reshape((7, 7, 384))(gen)\n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate()([gen, li])\n",
    "    # upsample to 14x14\n",
    "    gen = Conv2DTranspose(192, (5,5), strides=(2,2), padding=\"same\", kernel_initializer=init)(merge)\n",
    "    gen = BatchNormalization()(gen)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    # upsample to 28x28\n",
    "    gen = Conv2DTranspose(1, (5,5), strides=(2,2), padding=\"same\", kernel_initializer=init)(gen)\n",
    "    out_layer = Activation(\"tanh\")(gen)\n",
    "    # define model\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect the outputs of the generator to the inputs of the discriminator\n",
    "    gan_output = d_model(g_model.output)\n",
    "    # define gan model as taking noise and label and outputting real/fake and label outputs\n",
    "    model = Model(g_model.input, gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=[\"binary_crossentropy\", \"sparse_categorical_crossentropy\"], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "# load images\n",
    "def load_real_samples():\n",
    "    # load dataset\n",
    "    (trainX, trainy), (_, _) = load_data()\n",
    "    # expand to 3d, e.g. add channels\n",
    "    X = expand_dims(trainX, axis=-1)\n",
    "    # convert from ints to floats\n",
    "    X = X.astype(\"float32\")\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    print(X.shape, trainy.shape)\n",
    "    return [X, trainy]\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # split into images and labels\n",
    "    images, labels = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generate labels\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "    # prepare fake examples\n",
    "    [X, _], _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(100):\n",
    "        # define subplot\n",
    "        pyplot.subplot(10, 10, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis(\"off\")\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap=\"gray_r\")\n",
    "    # save plot to file\n",
    "    filename1 = \"C:\\\\_Thesis\\VirtualEnv\\\\__ganResults\\\\AC-GAN\\\\generated_plot_%04d.png\" % (step+1)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    filename2 = \"C:\\\\_Thesis\\\\VirtualEnv\\\\_models\\\\_AC-GAN\\\\model_%04d.h5\" % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    print(\">Saved: %s and %s\" % (filename1, filename2))\n",
    "\n",
    "    # train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=64):\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # get randomly selected ✬real✬ samples\n",
    "        [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "        # update discriminator model weights\n",
    "        _,d_r1,d_r2 = d_model.train_on_batch(X_real, [y_real, labels_real])\n",
    "        # generate ✬fake✬ examples\n",
    "        [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # update discriminator model weights\n",
    "        _,d_f,d_f2 = d_model.train_on_batch(X_fake, [y_fake, labels_fake])\n",
    "        # prepare points in latent space as input for the generator\n",
    "        [z_input, z_labels] = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = ones((n_batch, 1))\n",
    "        # update the generator via the discriminator✬s error\n",
    "        _,g_1,g_2 = gan_model.train_on_batch([z_input, z_labels], [y_gan, z_labels])\n",
    "        # summarize loss on this batch\n",
    "        print(\">%d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]\" % (i+1, d_r1,d_r2, d_f,d_f2,\n",
    "        g_1,g_2))\n",
    "        # evaluate the model performance every ✬epoch✬\n",
    "        if (i+1) % (bat_per_epo * 10) == 0:\n",
    "            summarize_performance(i, g_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "000,0.353], df[0.000,0.001], g[0.197,0.029]\n",
      ">31152, dr[0.000,0.335], df[0.000,0.001], g[0.186,0.020]\n",
      ">31153, dr[0.000,0.228], df[0.000,0.001], g[0.156,0.020]\n",
      ">31154, dr[0.000,0.237], df[0.000,0.007], g[0.256,0.015]\n",
      ">31155, dr[0.000,0.280], df[0.000,0.002], g[0.224,0.014]\n",
      ">31156, dr[0.000,0.502], df[0.000,0.001], g[0.330,0.017]\n",
      ">31157, dr[0.000,0.229], df[0.000,0.002], g[0.200,0.021]\n",
      ">31158, dr[0.000,0.300], df[0.000,0.001], g[0.115,0.022]\n",
      ">31159, dr[0.000,0.623], df[0.000,0.001], g[0.162,0.024]\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#####CALL TRAINING####\n",
    "######################\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "####GENERATE FUNCS#####\n",
    "#######################\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_class):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generate labels\n",
    "    labels = asarray([n_class for _ in range(n_samples)])\n",
    "    return [z_input, labels]\n",
    "\n",
    "# create and save a plot of generated images\n",
    "def show_plot(examples, n_examples):\n",
    "    # plot images\n",
    "    for i in range(n_examples):\n",
    "        # define subplot\n",
    "        pyplot.subplot(sqrt(n_examples), sqrt(n_examples), 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis(\"off\")\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(examples[i, :, :, 0], cmap=\"gray_r\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#####CALL GENERATE#####\n",
    "#######################\n",
    "\n",
    "# load model\n",
    "model = load_model(\"C:\\\\_Thesis\\\\VirtualEnv\\\\_models\\\\_AC-GAN\\\\model_93700.h5\")\n",
    "latent_dim = 100\n",
    "n_examples = 100 # must be a square\n",
    "n_class = 7 # sneaker\n",
    "# generate images\n",
    "latent_points, labels = generate_latent_points(latent_dim, n_examples, n_class)\n",
    "# generate images\n",
    "X = model.predict([latent_points, labels])\n",
    "# scale from [-1,1] to [0,1]\n",
    "X = (X + 1) / 2.0\n",
    "# plot the result\n",
    "show_plot(X, n_examples)"
   ]
  }
 ]
}